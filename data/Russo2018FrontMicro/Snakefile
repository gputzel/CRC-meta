configfile: "config.json"

SRP=config['SRP']
usearch_maxEE=config['usearch_maxEE']
IDS, = glob_wildcards("FASTQ/{id}_pass_1.fastq.gz")

from snakemake.remote.NCBI import RemoteProvider as NCBIRemoteProvider
NCBI = NCBIRemoteProvider(email=config['user_email']) 

from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider
HTTP = HTTPRemoteProvider()

import csv

with open('sample_data/SraRunTable.txt') as csvfile:
    reader = csv.DictReader(csvfile,delimiter='\t')
    SRR_runs = [row['Run'] for row in reader]

#rule download_runinfo:
#    output:
#        "sample_data/runinfo.csv"
#    shell:
#        'esearch -db sra -query "{SRP}" | efetch -format runinfo > sample_data/runinfo.csv'

rule download_xml:
    output:
        "sample_data/sra-info.xml"
    conda:
        "envs/entrez-direct.yaml"
    shell:
        'esearch -db sra -query "{SRP}" | efetch -format summary | xmllint --format - > sample_data/sra-info.xml'

rule get_sample_info:
    input:
        "sample_data/sra-info.xml"
    output:
        "sample_data/sample_info.csv"
    conda:
        "envs/get_sample_info.yaml"
    script:
        "scripts/get_sample_info.py"

rule join_sample_data:
    input:
        "sample_data/sample_info.csv",
        "sample_data/table1.tsv"
    output:
        "sample_data/merged_sample_data.tsv"
    conda:
        "envs/r-env.yaml"
    script:
        "scripts/join_sample_data.R"

rule select_samples:
    input:
        "sample_data/merged_sample_data.tsv"
    output:
        "sample_data/merged_sample_data_subset.tsv"
    conda:
        "envs/r-env.yaml"
    script:
        "scripts/select_samples.R"

rule download_sra:
    output:
        expand("FASTQ/{id}_pass_1.fastq.gz",id=SRR_runs),
        expand("FASTQ/{id}_pass_2.fastq.gz",id=SRR_runs)
    conda:
        "envs/sra-tools.yaml"
    run:
        for id in SRR_runs:
            shell("fastq-dump --outdir FASTQ --gzip --skip-technical --readids --read-filter pass --dumpbase --split-3 --clip {id}")

rule clear_fastq:
    input:
        "FASTQ"
    shell:
        "rm -r FASTQ"

rule fastqc:
    input:
        "FASTQ"
    output:
        "FASTQC/"
    conda:
        "envs/fastqc.yaml"
    shell:
        "scripts/fastqc.sh"

rule rename_fastq:
    input:
        expand("FASTQ_renamed/{id}_L001_R1_001.fastq.gz",id=IDS),
        expand("FASTQ_renamed/{id}_L001_R2_001.fastq.gz",id=IDS)

rule rename_fastq_onefile:
    input:
        "FASTQ/{SRR}_pass_{end}.fastq.gz"
    output:
        "FASTQ_renamed/{SRR}_L001_R{end}_001.fastq.gz"
    shell:
        "ln -s ../{input} {output}"

rule qiime2_import:
    input:
        expand("FASTQ_renamed/{id}_L001_R1_001.fastq.gz",id=IDS),
        expand("FASTQ_renamed/{id}_L001_R2_001.fastq.gz",id=IDS)
    output:
        "qiime2/fastq.qza"
    conda:
        "envs/qiime2-2018.2-py35-osx-conda.yml"
    shell:
        "scripts/qiime2_import.sh"

rule qiime2_dada2:
    input:
        "qiime2/fastq.qza"
    output:
        "qiime2/dada2/table.qza",
        "qiime2/dada2/rep_seqs.qza"
    log:
        "logs/qiime2/dada2"
    conda:
        "envs/qiime2-2018.2-py35-osx-conda.yml"
    shell:
        "scripts/qiime2_dada2.sh 2> {log}"

rule qiime2_format_metadata:
    input:
        "sample_data/merged_sample_data_subset.tsv"
    output:
        temp("qiime2/metadata.tsv")
    shell:
        "scripts/qiime2_format_metadata.sh"

rule qiime2_metadata_tabulate:
    input:
        "qiime2/metadata.tsv"
    output: 
        "qiime2/metadata.qzv"
    conda:
        "envs/qiime2-2018.2-py35-osx-conda.yml"
    shell:
        "qiime metadata tabulate --m-input-file {input} --o-visualization {output}"

rule qiime2_feature_table_summarize:
    input:
        table="qiime2/{method}/table.qza",
        metadata="qiime2/metadata.tsv"
    output:
        "qiime2/{method}/table.qzv"
    conda:
        "envs/qiime2-2018.2-py35-osx-conda.yml"
    shell:
        "qiime feature-table summarize" +
        " --i-table {input.table}" +
        " --o-visualization {output}" +
        " --m-sample-metadata-file {input.metadata}"

#rule usearch_decompress:
#    input:
#        "FASTQ_renamed"
#    output:
#        "usearch/FASTQ"
#    shell:
#        "scripts/usearch_decompress.sh"

rule usearch_decompress_fastq:
    input:
        expand("usearch/FASTQ/{id}_L001_R{end}_001.fastq",id=IDS,end=['1','2'])

rule usearch_decompress_fastq_onefile:
    input:
        "FASTQ_renamed/{file}.fastq.gz"
    output:
        "usearch/FASTQ/{file}.fastq"
    shell:
        "gzcat {input} > {output}"

rule usearch_fastq_info:
    input:
        expand("usearch/FASTQ_info/{id}_L001_R{end}_001.txt",id=IDS,end=['1','2'])

rule usearch_fasta_sample:
    input:
        expand("usearch/FASTA_sample/{id}_L001_R1_001.fasta",id=IDS)

rule usearch_fasta_sample_onefile:
    input:
        "usearch/FASTQ/{filename}.fastq"
    output:
        temp("usearch/FASTA_sample/{filename}.fasta")
    conda:
        "envs/seqtk.yaml"
    shell:
        "seqtk sample -s100 {input} 20 | seqtk seq -a - > {output}"

rule usearch_fasta_rc_sample:
    input:
        expand("usearch/FASTA_rc_sample/{id}_L001_R2_001.fasta",id=IDS)

rule usearch_fasta_rc_sample_onefile:
    input:
        "usearch/FASTQ/{filename}.fastq"
    output:
        temp("usearch/FASTA_rc_sample/{filename}.fasta")
    shell:
        "seqtk sample -s100 {input} 20 | seqtk seq -r - | seqtk seq -a - > {output}"

rule usearch_fasta_sample_interleave:
    input:
        forward="usearch/FASTA_sample/{filename}_R1_001.fasta",
        reverse="usearch/FASTA_rc_sample/{filename}_R2_001.fasta"
    output:
        temp("usearch/FASTA_sample_interleave/{filename}.fasta")
    conda:
        "envs/seqtk.yaml"
    shell:
        "seqtk mergepe {input.forward} {input.reverse} > {output}"

rule usearch_fastq_info_onefile:
    input:
        "usearch/FASTQ/{filename}.fastq"
    output:
        "usearch/FASTQ_info/{filename}.txt"
    shell:
        "usearch -fastx_info {input} -output {output}"

rule usearch_E_coli_ref:
    input:
        ecoli=NCBI.remote("J01859.1.fasta",db="nuccore")
    output:
        temp("usearch/E_coli_J01859.1.fasta")
    shell:
        "cp {input.ecoli} {output}"

rule usearch_cat_E_coli_ref:
    input:
        expand("usearch/FASTA_with_E_coli_ref/{id}.fasta",id=IDS)

rule usearch_cat_E_coli_ref_onefile:
    input:
        ecoli="usearch/E_coli_J01859.1.fasta",
        reads="usearch/FASTA_sample_interleave/{id}_L001.fasta"
    output:
        temp("usearch/FASTA_with_E_coli_ref/{id}.fasta")
    shell:
        "cat {input.ecoli} {input.reads} > {output}"

rule usearch_E_coli_align:
    input:
        expand("usearch/FASTA_E_coli_align/{id}.aln",id=IDS)

rule usearch_align_with_E_coli_ref_onefile:
    input:
        "usearch/FASTA_with_E_coli_ref/{id}.fasta"
    output:
        "usearch/FASTA_E_coli_align/{id}.aln"
    shell:
        "clustal_omega -i {input} > {output}"

rule usearch_fastq_eestats2:
    input:
        expand("usearch/eestats2/{id}_L001_R1_001.txt",id=IDS),
        expand("usearch/eestats2/{id}_L001_R2_001.txt",id=IDS)

rule usearch_fastq_eestats2_onefile:
    input:
        "usearch/FASTQ/{filename}.fastq",
    output:
        "usearch/eestats2/{filename}.txt"
    shell:
        "usearch -fastq_eestats2 {input} -output {output} -length_cutoffs 170,300,10"

rule usearch_fastq_mergepairs:
    input:
        expand("usearch/FASTQ/{id}_L001_R{end}_001.fastq",id=IDS,end=['1','2'])
    output:
        "usearch/merged.fq"
    shell:
        "usearch -fastq_mergepairs usearch/FASTQ/*R1*.fastq -relabel @ -fastq_maxdiffs 10 -fastq_pctid 80 -fastqout {output}"

rule usearch_fastq_filter:
    input:
        "usearch/merged.fq"
    output:
        "usearch/filtered.fa"
    shell:
        "usearch -fastq_filter {input} -fastq_maxee {usearch_maxEE} -fastaout {output}"

rule usearch_uniques:
    input:
        "usearch/filtered.fa"
    output:
        "usearch/uniques.fa"
    shell:
        "usearch -fastx_uniques {input} -fastaout {output} -sizeout -relabel Uniq"

rule usearch_cluster_otus:
    input:
        "usearch/uniques.fa",
    output:
        "usearch/otus.fa"
    shell:
        "usearch -cluster_otus {input} -otus {output} -relabel Otu"

rule usearch_otu_table:
    input:
        reads="usearch/merged.fq",
        otus="usearch/otus.fa",
    output:
        otutable="usearch/otutab.txt",
        map="usearch/map.txt"
    shell:
        "usearch -otutab {input.reads} -otus {input.otus} -otutabout {output.otutable} -mapout {output.map}"

rule usearch_decompress_SILVA:
    input:
        "usearch/ltp_16s_v123.fa.gz"
    output:
        "usearch/ltp_16s_v123.fa"
    shell:
        "gzcat {input} > {output}"

rule usearch_download_SILVA:
    input:
        silva_gz=HTTP.remote("https://www.drive5.com/sintax/ltp_16s_v123.fa.gz",keep_local=False) 
    output:
        temp("usearch/ltp_16s_v123.fa.gz")
    shell:
        "cp {input.silva_gz} {output}"

rule usearch_download_RDPtraining:
    input:
        RDP_gz=HTTP.remote("https://www.drive5.com/sintax/rdp_16s_v16.fa.gz",keep_local=False)
    output:
        "usearch/rdp_16s_v16.fa"
    shell:
        "gzcat {input} > {output}"

rule usearch_makeudb_sintax:
    input:
        "usearch/{database}.fa"
    output:
        "usearch/{database}.udb"
    shell:
        "usearch -makeudb_sintax {input} -output {output}"

rule usearch_sintax:
    input:
        db="usearch/rdp_16s_v16.udb",
        otus="usearch/otus.fa"
    output:
        "usearch/taxonomy.txt"
    log: "logs/usearch/taxonomy.log"
    shell:
        "usearch -sintax {input.otus} -db {input.db} -tabbedout {output} -strand both -sintax_cutoff 0.8 2> {log}"

rule usearch_maketree:
    input:
        "usearch/otus.fa"
    output:
        "usearch/otus.tre"
    log: "logs/usearch/maketree.log"
    shell:
        "usearch -cluster_agg {input} -treeout {output} 2> {log}"

rule usearch_to_phyloseq:
    input:
        otu_table="usearch/otutab.txt",
        taxonomy="usearch/taxonomy.txt",
        tree="usearch/otus.tre",
        sample_data="sample_data/merged_sample_data_subset.tsv"
    output:
        ps_file="usearch/ps_usearch.rds"
    script:
        "scripts/usearch_to_phyloseq.R"

rule:
    input:
        "FASTQ/{id}_pass_1.fastq.gz"
    output:
        temp("E_coli_align/{id}_1.fasta")
    conda:
        "envs/seqtk.yaml"
    shell:
        "seqtk sample -s100 {input} 20 | seqtk seq -a - > {output}"

rule:
    input:
        "FASTQ/{id}_pass_2.fastq.gz"
    output:
        temp("E_coli_align/{id}_2.fasta")
    conda:
        "envs/seqtk.yaml"
    shell:
        "seqtk sample -s100 {input} 20 | seqtk seq -r - | seqtk seq -a - > {output}"

rule:
    input:
        forward="E_coli_align/{id}_1.fasta",
        reverse="E_coli_align/{id}_2.fasta"
    output:
        temp("E_coli_align/{id}_combined.fasta")
    conda:
        "envs/seqtk.yaml"
    shell:
        "seqtk mergepe {input.forward} {input.reverse} > {output}"

rule E_coli_ref:
    input:
        ecoli=NCBI.remote("J01859.1.fasta",db="nuccore")
    output:
        temp("E_coli_align/E_coli_J01859.1.fasta")
    shell:
        "cp {input.ecoli} {output}"

rule:
    input:
        ecoli="E_coli_align/E_coli_J01859.1.fasta",
        reads="E_coli_align/{id}_combined.fasta"
    output:
        temp("E_coli_align/{id}_combined_with_E_coli.fasta")
    shell:
        "cat {input.ecoli} {input.reads} > {output}"

rule:
    input:
        "E_coli_align/{id}_combined_with_E_coli.fasta"
    output:
        "E_coli_align/{id}.aln"
    shell:
        "clustal_omega -i {input} > {output}"

rule E_coli_align:
    input:
        expand("E_coli_align/{id}.aln",id=SRR_runs)

rule qiime1_join_paired_ends:
    input:
        expand("qiime1/FASTQ_joined/{id}",id=SRR_runs)

rule:
    input:
        forward="FASTQ/{id}_pass_1.fastq.gz",
        reverse="FASTQ/{id}_pass_2.fastq.gz"
    output:
        "qiime1/FASTQ_joined/{id}"
    shell:
       "join_paired_ends.py -f {input.forward} -r {input.reverse} -o {output}"

rule qiime1_joined_all:
    input:
        expand("qiime1/FASTQ_joined/{id}/fastqjoin.join.fastq",id=SRR_runs)
    output:
        expand("qiime1/FASTQ_joined_all/{id}.fastq",id=SRR_runs)
    run:
        for id in SRR_runs:
            shell("ln -s ../FASTQ_joined/{id}/fastqjoin.join.fastq qiime1/FASTQ_joined_all/{id}.fastq")

rule qiime1_split_libraries:
    input:
        expand("qiime1/FASTQ_joined_all/{id}.fastq",id=SRR_runs)
    output:
        "qiime1/split_libraries"
    shell:
        "multiple_split_libraries_fastq.py -i qiime1/FASTQ_joined_all -p qiime1_params/split_libraries_fastq_params.txt -o qiime1/split_libraries --demultiplexing_method sampleid_by_file --sampleid_indicator ."

rule qiime1_identify_chimeras:
    input:
        "qiime1/split_libraries/seqs.fna"
    output:
        "qiime1/chimera_check_usearch61"
    shell:
        "identify_chimeric_seqs.py -m usearch61 -i qiime1/split_libraries/seqs.fna -r {greengenes_13_8_path}/rep_set/97_otus.fasta -o qiime1/chimera_check_usearch61"

rule qiime1_remove_chimeras:
    input:
        "qiime1/chimera_check_usearch61"
    output:
        "qiime1/remove_chimeras/seqs.fna"
    shell:
        "filter_fasta.py -f qiime1/split_libraries/seqs.fna -s qiime1/chimera_check_usearch61/chimeras.txt -o qiime1/remove_chimeras/seqs.fna -n"

rule qiime1_pick_otus:
    input:
        "qiime1/remove_chimeras/seqs.fna"
    output:
        "qiime1/otus_chimera_removed"
    shell:
        "pick_open_reference_otus.py -i qiime1/remove_chimeras/seqs.fna -o qiime1/otus_chimera_removed -p qiime1_params/uc_fast_params.txt"

rule qiime1_to_phyloseq:
    input:
        biom="qiime1/otus_chimera_removed/otu_table_mc2_w_tax_no_pynast_failures.biom",
        tree="qiime1/otus_chimera_removed/rep_set.tre"
    output:
        "qiime1/ps_qiime1.rds"
    script:
        "scripts/qiime1_to_phyloseq.R"
