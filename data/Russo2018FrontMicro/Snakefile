configfile: "config.json"

SRP=config['SRP']
usearch_maxEE=config['usearch_maxEE']
IDS, = glob_wildcards("FASTQ/{id}_pass_1.fastq.gz")

from snakemake.remote.NCBI import RemoteProvider as NCBIRemoteProvider
NCBI = NCBIRemoteProvider(email=config['user_email']) 

from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider
HTTP = HTTPRemoteProvider()

#rule download_runinfo:
#    output:
#        "sample_data/runinfo.csv"
#    shell:
#        'esearch -db sra -query "{SRP}" | efetch -format runinfo > sample_data/runinfo.csv'

rule download_xml:
    output:
        "sample_data/sra-info.xml"
    conda:
        "envs/entrez-direct.yaml"
    shell:
        'esearch -db sra -query "{SRP}" | efetch -format summary | xmllint --format - > sample_data/sra-info.xml'

rule get_sample_info:
    input:
        "sample_data/sra-info.xml"
    output:
        "sample_data/sample_info.csv"
    conda:
        "envs/get_sample_info.yaml"
    script:
        "scripts/get_sample_info.py"

rule join_sample_data:
    input:
        "sample_data/sample_info.csv",
        "sample_data/table1.tsv"
    output:
        "sample_data/merged_sample_data.tsv"
    conda:
        "envs/r-env.yaml"
    script:
        "scripts/join_sample_data.R"

rule select_samples:
    input:
        "sample_data/merged_sample_data.tsv"
    output:
        "sample_data/merged_sample_data_subset.tsv"
    conda:
        "envs/r-env.yaml"
    script:
        "scripts/select_samples.R"

rule download_sra:
    input:
        "sample_data/merged_sample_data_subset.tsv"
    output:
        "FASTQ"
    conda:
        "envs/sra-tools.yaml"
    shell:
        "scripts/download_sra.sh"

rule clear_fastq:
    input:
        "FASTQ"
    shell:
        "rm -r FASTQ"

rule fastqc:
    input:
        "FASTQ"
    output:
        "FASTQC/"
    conda:
        "envs/fastqc.yaml"
    shell:
        "scripts/fastqc.sh"

rule rename_fastq:
    input:
        "FASTQ"
    output:
        "FASTQ_renamed/"
    shell:
        "scripts/rename_fastq.sh"

rule qiime2_import:
    input:
        "FASTQ_renamed/"
    output:
        "qiime2/fastq.qza"
    conda:
        "envs/qiime2-2018.2-py35-osx-conda.yml"
    shell:
        "scripts/qiime2_import.sh"

rule qiime2_dada2:
    input:
        "qiime2/fastq.qza"
    output:
        "qiime2/dada2/table.qza",
        "qiime2/dada2/rep_seqs.qza"
    conda:
        "envs/qiime2-2018.2-py35-osx-conda.yml"
    shell:
        "scripts/qiime2_dada2.sh"

rule usearch_decompress:
    input:
        "FASTQ_renamed"
    output:
        "usearch/FASTQ"
    shell:
        "scripts/usearch_decompress.sh"

rule usearch_fastq_info:
    input:
        expand("usearch/FASTQ_info/{id}_1_L001_R1_001.txt",id=IDS),
        expand("usearch/FASTQ_info/{id}_1_L001_R2_001.txt",id=IDS),

rule usearch_fasta_sample:
    input:
        expand("usearch/FASTA_sample/{id}_1_L001_R1_001.fasta",id=IDS)

rule usearch_fasta_sample_onefile:
    input:
        "usearch/FASTQ/{filename}.fastq"
    output:
        temp("usearch/FASTA_sample/{filename}.fasta")
    conda:
        "envs/seqtk.yaml"
    shell:
        "seqtk sample -s100 {input} 10 | seqtk seq -a - > {output}"

rule usearch_fasta_rc_sample:
    input:
        expand("usearch/FASTA_rc_sample/{id}_1_L001_R2_001.fasta",id=IDS)

rule usearch_fasta_rc_sample_onefile:
    input:
        "usearch/FASTQ/{filename}.fastq"
    output:
        temp("usearch/FASTA_rc_sample/{filename}.fasta")
    shell:
        "seqtk sample -s100 {input} 10 | seqtk seq -r - | seqtk seq -a - > {output}"

rule usearch_fastq_info_onefile:
    input:
        "usearch/FASTQ/{filename}.fastq"
    output:
        "usearch/FASTQ_info/{filename}.txt"
    shell:
        "usearch -fastx_info {input} -output {output}"

rule usearch_E_coli_ref:
    input:
        ecoli=NCBI.remote("J01859.1.fasta",db="nuccore")
    output:
        temp("usearch/E_coli_J01859.1.fasta")
    shell:
        "cp {input.ecoli} {output}"

rule usearch_cat_E_coli_ref:
    input:
        expand("usearch/FASTA_with_E_coli_ref/{id}.fasta",id=IDS)

rule usearch_cat_E_coli_ref_onefile:
    input:
        ecoli="usearch/E_coli_J01859.1.fasta",
        forward="usearch/FASTA_sample/{id}_1_L001_R1_001.fasta",
        reverse="usearch/FASTA_rc_sample/{id}_1_L001_R2_001.fasta"
    output:
        temp("usearch/FASTA_with_E_coli_ref/{id}.fasta")
    shell:
        "cat {input.ecoli} {input.forward} {input.reverse} > {output}"

rule usearch_align_with_E_coli_ref:
    input:
        expand("usearch/FASTA_E_coli_align/{id}.aln",id=IDS)

rule usearch_align_with_E_coli_ref_onefile:
    input:
        "usearch/FASTA_with_E_coli_ref/{id}.fasta"
    output:
        "usearch/FASTA_E_coli_align/{id}.aln"
    shell:
        "clustal_omega -i {input} > {output}"

rule usearch_fastq_eestats2:
    input:
        expand("usearch/eestats2/{id}_1_L001_R1_001.txt",id=IDS),
        expand("usearch/eestats2/{id}_1_L001_R2_001.txt",id=IDS)

rule usearch_fastq_eestats2_onefile:
    input:
        "usearch/FASTQ/{filename}.fastq",
    output:
        "usearch/eestats2/{filename}.txt"
    shell:
        "usearch -fastq_eestats2 {input} -output {output} -length_cutoffs 170,300,10"

rule usearch_fastq_mergepairs:
    input:
        expand("usearch/FASTQ/{id}_1_L001_R1_001.fastq",id=IDS),
        expand("usearch/FASTQ/{id}_1_L001_R2_001.fastq",id=IDS)
    output:
        "usearch/merged.fq"
    shell:
        "usearch -fastq_mergepairs usearch/FASTQ/*R1*.fastq -relabel @ -fastq_maxdiffs 10 -fastq_pctid 80 -fastqout {output}"

rule usearch_fastq_filter:
    input:
        "usearch/merged.fq"
    output:
        "usearch/filtered.fa"
    shell:
        "usearch -fastq_filter {input} -fastq_maxee {usearch_maxEE} -fastaout {output}"

rule usearch_uniques:
    input:
        "usearch/filtered.fa"
    output:
        "usearch/uniques.fa"
    shell:
        "usearch -fastx_uniques {input} -fastaout {output} -sizeout -relabel Uniq"

rule usearch_cluster_otus:
    input:
        "usearch/uniques.fa",
    output:
        "usearch/otus.fa"
    shell:
        "usearch -cluster_otus {input} -otus {output} -relabel Otu"

rule usearch_otu_table:
    input:
        reads="usearch/merged.fq",
        otus="usearch/otus.fa",
    output:
        otutable="usearch/otutab.txt",
        map="usearch/map.txt"
    shell:
        "usearch -otutab {input.reads} -otus {input.otus} -otutabout {output.otutable} -mapout {output.map}"

rule usearch_decompress_SILVA:
    input:
        "usearch/ltp_16s_v123.fa.gz"
    output:
        "usearch/ltp_16s_v123.fa"
    shell:
        "gzcat {input} > {output}"

rule usearch_download_SILVA:
    input:
        silva_gz=HTTP.remote("https://www.drive5.com/sintax/ltp_16s_v123.fa.gz",keep_local=False) 
    output:
        temp("usearch/ltp_16s_v123.fa.gz")
    shell:
        "cp {input.silva_gz} {output}"

rule usearch_download_RDPtraining:
    input:
        RDP_gz=HTTP.remote("https://www.drive5.com/sintax/rdp_16s_v16.fa.gz",keep_local=False)
    output:
        "usearch/rdp_16s_v16.fa"
    shell:
        "gzcat {input} > {output}"

rule usearch_makeudb_sintax:
    input:
        "usearch/{database}.fa"
    output:
        "usearch/{database}.udb"
    shell:
        "usearch -makeudb_sintax {input} -output {output}"

rule usearch_sintax:
    input:
        db="usearch/rdp_16s_v16.udb",
        otus="usearch/otus.fa"
    output:
        "usearch/taxonomy.txt"
    log: "logs/usearch/taxonomy.log"
    shell:
        "usearch -sintax {input.otus} -db {input.db} -tabbedout {output} -strand both -sintax_cutoff 0.8 2> {log}"

rule usearch_maketree:
    input:
        "usearch/otus.fa"
    output:
        "usearch/otus.tre"
    log: "logs/usearch/maketree.log"
    shell:
        "usearch -cluster_agg {input} -treeout {output} 2> {log}"

rule usearch_to_phyloseq:
    input:
        otu_table="usearch/otutab.txt",
        taxonomy="usearch/taxonomy.txt",
        tree="usearch/otus.tre",
        sample_data="sample_data/merged_sample_data_subset.tsv"
    output:
        ps_file="usearch/ps_usearch.rds"
    script:
        "scripts/usearch_to_phyloseq.R"
